{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Reservoir Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "This notebook describes how reservoir release rules are determined for CWatM, and compares observed and simulated reservoir data at several reservoirs in the Nira river sub-basin of the Upper Bhima basin.\n",
    "\n",
    "Currently, the following data are being used:\n",
    " - Reservoir levels\n",
    " - Discharge\n",
    " - Inflow\n",
    " - Irrigation use\n",
    " \n",
    "The observed data for which we compare CWatM simulated reservoir levels are kindly offered on behalf of the National Hydrological Project, India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available information related to reservoir releases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "## File locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'C:/CWatM_output/act_bigLakeResAbst_alloc_daily.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1956eb3de71f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mVars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mreservoir_nc_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_daily.nc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mSIMULATED_nc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreservoir_nc_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mnetCDF4\\_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnetCDF4\\_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'C:/CWatM_output/act_bigLakeResAbst_alloc_daily.nc'"
     ]
    }
   ],
   "source": [
    "fuse_folder_local = 'C:/GitHub/FUSE'\n",
    "fuse_folder_github = 'C:/GitHub/FUSE'\n",
    "cwatm_folder_local = fuse_folder_local + '/CWATM'\n",
    "output_folder =  'C:/CWatM_output'\n",
    "\n",
    "photo_folder = fuse_folder_github + '/Images'\n",
    "measuredData_folder = fuse_folder_local + '/Data_forNotebooks/Reservoir_Historical/Reservoir level_inflow_floodcontrol'\n",
    "\n",
    "#Dam_names = ['Vir','Gunjvane', 'NiraDeoghar', 'Bhatghar']\n",
    "#Inds =  [(164,111), (143,55), (168,66), (159,84)]\n",
    "\n",
    "#Dam_names = ['Vir', 'Bhatghar']\n",
    "#Inds =  [(164,111), (159,84)]\n",
    "\n",
    "Dam_names = ['Vir', 'NiraDeoghar', 'Bhatghar']\n",
    "Inds =  [(164,111), (168,66), (159,84)]\n",
    "\n",
    "Reservoirs_Sarati = Dam_names\n",
    "\n",
    "Vars = [['lakeResStorage', 'Lake Level', 'Reservoir Volume', 'Volume (MCM)', 1000000.],\n",
    "        ['lakeResOutflowDis', 'Spilling', 'Reservoir Outflow', 'Outflow (m3/s)', 1.], \n",
    "        ['lakeResInflowDis', 'positive', 'Reservoir Inflow', 'Inflow (m3/s)', 1.],\n",
    "        ['act_bigLakeResAbst_alloc', 'Irrigation Use', 'Irrigation Use', 'Volume (MCM)', 1000000.]]\n",
    "\n",
    "        #['lakeResStorage_alloc', '', 'Total water in segment', 'Volume (MCM)', 1000000.]] \n",
    "\n",
    "SIMULATED_nc = []\n",
    "\n",
    "for var in Vars:\n",
    "    reservoir_nc_filename = output_folder +'/'+ var[0] + '_daily.nc'\n",
    "    SIMULATED_nc.append(Dataset(reservoir_nc_filename, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Here, we present the locations and names of the reservoirs of interest.\n",
    "\n",
    "Ujjani reservoir is only shown for spatial context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "img = Image.open(photo_folder + '/reservoirs_onSarati.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "Dates_simulation = num2date(SIMULATED_nc[0].variables['time'][:], units=SIMULATED_nc[0].variables['time'].units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "The below block of code can be activated to list the locations of the reservoir outlet points ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "Storage = SIMULATED_nc[0].variables['lakeResStorage'][1,:,:]\n",
    "reservoirs = []\n",
    "\n",
    "for i in range(SIMULATED_nc[0].variables['lat'].shape[0]):\n",
    "    for j in range (SIMULATED_nc[0].variables['lon'].shape[0]):\n",
    "        if Storage[i,j] > 0:\n",
    "            \n",
    "            reservoirs.append([Storage[i,j], i, j])\n",
    "            \n",
    "print(reservoirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "DAMS = []\n",
    "\n",
    "for i in range(len(Vars)): \n",
    "    Dams = []\n",
    "    for inds in Inds:\n",
    "        Dams.append(SIMULATED_nc[i].variables[Vars[i][0]][:,inds[0], inds[1]]/Vars[i][4])\n",
    "    DAMS.append(Dams)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "## CWatM Simulations: \n",
    " - Volumes\n",
    " - Discharge\n",
    " - Inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Vars)):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    Dams = DAMS[i]\n",
    "    \n",
    "    for dam_i in range(len(Dams)):\n",
    "        \n",
    "        fig.add_trace(go.Scatter(y=Dams[dam_i],\n",
    "                                 x=Dates_simulation,\n",
    "                        mode='lines',\n",
    "                        name=Dam_names[dam_i]))\n",
    "\n",
    "\n",
    "    fig.update_layout(title = Vars[i][2] +', Simulated',\n",
    "                           xaxis_title='Days',\n",
    "                           yaxis_title= Vars[i][3])\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Analysing observed reservoir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xlrd\n",
    "import os   \n",
    "\n",
    "VARS_DATES = []\n",
    "VARS_LEVELS = []\n",
    "VARS_Reservoirs_withLevel = []\n",
    "\n",
    "Reservoirs = os.listdir(measuredData_folder)\n",
    "\n",
    "for var in Vars:\n",
    "    \n",
    "    DATES = []\n",
    "    LEVELS = []\n",
    "    Reservoirs_withLevel = []\n",
    "\n",
    "    for reservoir in Reservoirs:\n",
    "\n",
    "        find_file = [var[1] +'.xlsx' in i for i in os.listdir(measuredData_folder +'/'+ reservoir)]\n",
    "\n",
    "        if True in find_file:\n",
    "\n",
    "            filename = os.listdir(measuredData_folder +'/'+ reservoir)[find_file.index(True)]\n",
    "\n",
    "            book = xlrd.open_workbook(measuredData_folder  +'/'+ reservoir +'/'+ filename)\n",
    "            sheet = book.sheet_by_index(0)\n",
    "            num_rows = sheet.nrows\n",
    "\n",
    "            Dates_fromExcel = [xlrd.xldate_as_tuple(int(sheet.cell(row,0).value), 0) for row in range(2, num_rows)]\n",
    "            Dates = [datetime.datetime(d[0], d[1], d[2]) for d in Dates_fromExcel]\n",
    "\n",
    "            Levels = [sheet.cell(row, 1).value for row in range(2, num_rows)]\n",
    "\n",
    "\n",
    "            DATES.append(Dates)\n",
    "            LEVELS.append(Levels)\n",
    "            Reservoirs_withLevel.append(reservoir)\n",
    "\n",
    "        else:\n",
    "            print('Missing file: '+ var[2] +': '+ reservoir)\n",
    "                \n",
    "    VARS_DATES.append(DATES)\n",
    "    VARS_LEVELS.append(LEVELS)\n",
    "    VARS_Reservoirs_withLevel.append(Reservoirs_withLevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def level_to_volume(level, reservoir):\n",
    "\n",
    "    if level == '':\n",
    "        volume = ''\n",
    "    else:\n",
    "        if reservoir == 'Veer' or reservoir =='Vir':\n",
    "            volume = 0.5312*level**2 - 591.26*level + 164526\n",
    "        elif reservoir == 'Bhatghar':\n",
    "            \n",
    "            # -0,0003x4 + 0,7976x3 - 719,23x2 + 287999x - 4E+07\n",
    "            # Jan 25 commented out volume = 0.5129241275659454*level**2 -602.0396530087479*level + 176662.66875475977\n",
    "            #volume = 0.4836*level**2 -566.54*level + 165930\n",
    "            volume = 0.4836*level**2 -566.54*level + 165923\n",
    "            \n",
    "            \n",
    "            # volume = 0.4641*level**2 - 542.84*level + 158709\n",
    "        elif reservoir in ['NiraDeoghar', 'NiraDevdhar']:\n",
    "            volume = 0.1543*level**2 - 191.37*level + 59331\n",
    "        elif reservoir == 'Gunjvane':\n",
    "            volume = y = 0.0988*level**2 - 137.62*level + 47935\n",
    "\n",
    "    \n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VARS_MISSING_dates = []\n",
    "VARS_LEVELS_removeNoData = []\n",
    "VARS_DATES_removeNoData = []\n",
    "\n",
    "\n",
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    MISSING_dates = []\n",
    "    LEVELS_removeNoData = []\n",
    "    DATES_removeNoData = []\n",
    "\n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        missing_dates = []\n",
    "        Levels_removeNoData = []\n",
    "        Dates_removeNoData = []\n",
    "\n",
    "        Levels = VARS_LEVELS[var_i][res_i]\n",
    "        Dates = VARS_DATES[var_i][res_i]\n",
    "\n",
    "\n",
    "        for i in range(len(Levels)):\n",
    "\n",
    "            if Levels[i] == '' or Levels[i] == 0:\n",
    "                missing_dates.append(Dates[i])\n",
    "            else:\n",
    "                Levels_removeNoData.append(Levels[i])\n",
    "                Dates_removeNoData.append(Dates[i])\n",
    "\n",
    "        percent_missing = int(len(missing_dates)/len(Levels)*100)\n",
    "\n",
    "        print(Vars[var_i][2])\n",
    "        print(VARS_Reservoirs_withLevel[var_i][res_i])\n",
    "        #print(Reservoirs_withLevel[res_i])\n",
    "        \n",
    "        #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] +': '+str(percent_missing) + ' % of the values are missing.')\n",
    "        print(Vars[var_i][2] + ' for '+ VARS_Reservoirs_withLevel[var_i][res_i] +': '+str(percent_missing) + ' % of the values are missing.')\n",
    "\n",
    "        \n",
    "        MISSING_dates.append(missing_dates)\n",
    "        LEVELS_removeNoData.append(Levels_removeNoData)\n",
    "        DATES_removeNoData.append(Dates_removeNoData)                    \n",
    "            \n",
    "    VARS_MISSING_dates.append(MISSING_dates)\n",
    "    VARS_LEVELS_removeNoData.append(LEVELS_removeNoData)\n",
    "    VARS_DATES_removeNoData.append(DATES_removeNoData)\n",
    "    print('\\n')\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "VARS_VOLUMES_removeNoData = []\n",
    "\n",
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    VOLUMES_removeNoData = []\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(Reservoirs_withLevel)):\n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati:\n",
    "            \n",
    "            Levels = VARS_LEVELS_removeNoData[var_i][res_i]\n",
    "            \n",
    "            if Vars[var_i][1] == 'Lake Level':\n",
    "                Volumes = [level_to_volume(level, Reservoirs_withLevel[res_i]) for level in Levels]\n",
    "                \n",
    "            elif Vars[var_i][1] == 'Irrigation Use':\n",
    "                Volumes = np.array(Levels)*60*60*24/1000000\n",
    "            else:\n",
    "                Volumes = Levels\n",
    "                \n",
    "            Volumes_corrected = [volume if volume=='' or volume<3500 else '' for volume in Volumes]\n",
    "                \n",
    "            VOLUMES_removeNoData.append(Volumes_corrected)\n",
    "            \n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The maximum is ' + str(max(Volumes_corrected)))\n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The minimum is ' + str(min(Volumes_corrected)))\n",
    "\n",
    "        else:\n",
    "            VOLUMES_removeNoData.append([])\n",
    "    \n",
    "    VARS_VOLUMES_removeNoData.append(VOLUMES_removeNoData)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "# Visualisations\n",
    "## Reservoir Volumes, Outflows, and Inflows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true
   },
   "source": [
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati: \n",
    "            \n",
    "            #Dates = VARS_DATES[var_i][res_i]\n",
    "            #Volumes = VARS_VOLUMES[var_i][res_i]\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = VARS_DATES_removeNoData[var_i][res_i],\n",
    "                                     y = VARS_VOLUMES_removeNoData[var_i][res_i], \n",
    "                                     mode='markers',\n",
    "                                     name='Measured'))\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = Dates_simulation, #x,\n",
    "                                     y = DAMS[var_i][Dam_names.index(Reservoirs_withLevel[res_i])],\n",
    "                                     mode='lines',\n",
    "                                     name='Simulated'))\n",
    "\n",
    "            fig.update_layout(title= Vars[var_i][2] +': '+ Reservoirs_withLevel[res_i],\n",
    "                                   xaxis_title='Date (Day)',\n",
    "                                   yaxis_title= Vars[var_i][3])\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "VARS_VOLUMES = []\n",
    "\n",
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    VOLUMES = []\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(Reservoirs_withLevel)):\n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati:\n",
    "            \n",
    "            Levels = VARS_LEVELS[var_i][res_i]\n",
    "            \n",
    "            if Vars[var_i][1] == 'Lake Level':\n",
    "                Volumes = [level_to_volume(level, Reservoirs_withLevel[res_i]) for level in Levels]\n",
    "                \n",
    "            elif Vars[var_i][1] == 'Irrigation Use':\n",
    "                Volumes = np.array(Levels)*60*60*24/1000000\n",
    "            else:\n",
    "                Volumes = Levels\n",
    "                \n",
    "            Volumes_corrected = [volume if volume=='' or volume<3500 else '' for volume in Volumes]\n",
    "                \n",
    "            VOLUMES.append(Volumes_corrected)\n",
    "            \n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The maximum is ' + str(max(Volumes_corrected)))\n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The minimum is ' + str(min(Volumes_corrected)))\n",
    "\n",
    "        else:\n",
    "            VOLUMES.append([])\n",
    "    \n",
    "    VARS_VOLUMES.append(VOLUMES)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Visualisations\n",
    "## Reservoir Volumes, Outflows, and Inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati: \n",
    "            \n",
    "            Dates = VARS_DATES[var_i][res_i]\n",
    "            Volumes = VARS_VOLUMES[var_i][res_i]\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = VARS_DATES[var_i][res_i],\n",
    "                                     y = VARS_VOLUMES[var_i][res_i], \n",
    "                                     mode='lines',\n",
    "                                     name='Measured'))\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = Dates_simulation, #x,\n",
    "                                     y = DAMS[var_i][Dam_names.index(Reservoirs_withLevel[res_i])],\n",
    "                                     mode='lines',\n",
    "                                     name='Simulated'))\n",
    "\n",
    "            fig.update_layout(title= Vars[var_i][2] +': '+ Reservoirs_withLevel[res_i],\n",
    "                                   xaxis_title='Date (Day)',\n",
    "                                   yaxis_title= Vars[var_i][3])\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Reservoirs_withLevel[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for var_i in range(len(Vars)):\n",
    "for var_i in [3]:\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati: \n",
    "            \n",
    "            Dates = VARS_DATES[var_i][res_i]\n",
    "            Volumes = VARS_VOLUMES[var_i][res_i]\n",
    "            fig = go.Figure()\n",
    "\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = VARS_DATES[var_i][res_i],\n",
    "                                     y = VARS_VOLUMES[var_i][res_i], \n",
    "                                     mode='lines',\n",
    "                                     name='Measured'))\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = Dates_simulation, #x,\n",
    "                                     y = DAMS[var_i][Dam_names.index(Reservoirs_withLevel[res_i])],\n",
    "                                     mode='lines',\n",
    "                                     name='Simulated'))\n",
    "\n",
    "            fig.update_layout(title= Vars[var_i][2] +': '+ Reservoirs_withLevel[res_i],\n",
    "                                   xaxis_title='Date (Day)',\n",
    "                                   yaxis_title= Vars[var_i][3])\n",
    "\n",
    "            fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_first = Dates[0].year\n",
    "year_last = Dates[-1].year\n",
    "years_i = []\n",
    "            \n",
    "for year in range(year_first, year_last):\n",
    "    years_i.append(Dates.index(datetime.datetime(year, 6, 1, 0, 0)))\n",
    "\n",
    "# datetime.datetime(1964, 6, 1, 0, 0)\n",
    "# datetime.datetime(2008, 5, 31, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(len(years_i)-1):\n",
    "    fig.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                             y = Volumes[years_i[i]: years_i[i+1]],\n",
    "                             mode='lines',\n",
    "                             name='Measured'))\n",
    "\n",
    "Dates[years_i[0]: years_i[1]]\n",
    "\n",
    "Daily_discharge_average = [mean([Volumes[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)]\n",
    "\n",
    "fig.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                         y = Daily_discharge_average,\n",
    "                         mode='lines',\n",
    "                         name='Measured'))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig2 = go.Figure()\n",
    "for i in range(1): #(len(years_i)-1):\n",
    "    fig2.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                             y = Volumes[years_i[i]: years_i[i+1]],\n",
    "                             mode='lines',\n",
    "                             name='Measured'))\n",
    "\n",
    "Daily_discharge_average = [mean([Volumes[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)]\n",
    "\n",
    "fig2.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                         y = Daily_discharge_average,\n",
    "                         mode='lines',\n",
    "                         name='Measured'))\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Irrigation discharge normalized by reservoir volume\n",
    "\n",
    "#Volume_np = np.array(VARS_VOLUMES[0][18]) #Volume\n",
    "Volumes_woBlank = []\n",
    "#Irrigation_np = VARS_VOLUMES[3][16] #Irrigation\n",
    "Irrigation_woBlank = []\n",
    "#Irr_overVolume = Irrigation_np/Volume_np\n",
    "\n",
    "\n",
    "for i in VARS_VOLUMES[0][18]:\n",
    "    if i=='':\n",
    "        Volumes_woBlank.append(0)\n",
    "    else:\n",
    "        Volumes_woBlank.append(i)\n",
    "        \n",
    "for i in VARS_VOLUMES[3][16]:\n",
    "    if i=='':\n",
    "        Irrigation_woBlank.append(0)\n",
    "    else:\n",
    "        Irrigation_woBlank.append(i)\n",
    "        \n",
    "Volume_np = np.array(Volumes_woBlank)\n",
    "Irrigation_np = np.array(Irrigation_woBlank)\n",
    " \n",
    "print(len(Volume_np))\n",
    "print(len(Irrigation_np))\n",
    "\n",
    "#x = Irrigation_np/Volume_np\n",
    "Irr_overVolume = [Irrigation_np[i]/Volume_np[i] if Volume_np[i]>0 else 0 for i in range(len(Volume_np))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statistics import mean, median\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(years_i)-1):\n",
    "    fig.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                         y = Irr_overVolume[years_i[i]: years_i[i+1]],\n",
    "                         mode='lines',\n",
    "                         name='Measured'))\n",
    "\n",
    "\n",
    "\n",
    "Dates[years_i[0]: years_i[1]]\n",
    "\n",
    "Daily_discharge_average = [mean([Irr_overVolume[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)]\n",
    "\n",
    "fig.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                         y = Daily_discharge_average,\n",
    "                         mode='lines',\n",
    "                         name='Mean'))\n",
    "\n",
    "Daily_discharge_median = [median([Irr_overVolume[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)]\n",
    "\n",
    "fig.add_trace(go.Scatter(x = Dates[years_i[0]: years_i[1]],\n",
    "                         y = Daily_discharge_median,\n",
    "                         mode='lines',\n",
    "                         name='Median'))\n",
    "\n",
    "#fig2 = go.Figure(data=[go.Box([Volumes[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)])\n",
    "#fig2 = go.Figure(data=[go.Box([Volumes[years_i[0] : years_i[1]][day], Volumes[years_i[1] : years_i[2]][day]]) for day in range(2)])\n",
    "\n",
    "#fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_of_year = [i.timetuple().tm_yday for i in Dates[years_i[0]: years_i[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [[DAYS_of_year[i], Daily_discharge_median[i]] for i in range(len(DAYS_of_year))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [i[1] for i in tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fractions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"{0:0=2d}\".format(x[0].day)+'/'+\"{0:0=2d}\".format(x[0].month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "# Create a workbook and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook('Test_irrigation.xlsx')\n",
    "worksheet = workbook.add_worksheet('Veer_median')\n",
    "\n",
    "# Some data we want to write to the worksheet.\n",
    "x = Dates[years_i[0]: years_i[1]]\n",
    "y = Daily_discharge_median\n",
    "\n",
    "x_forExcel = [\"{0:0=2d}\".format(d.day)+'/'+\"{0:0=2d}\".format(d.month) for d in x]\n",
    "\n",
    "# Start from the first cell. Rows and columns are zero indexed.\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "# Iterate over the data and write it out row by row.\n",
    "for i in range(len(x)):\n",
    "    worksheet.write(row, col,     str(x_forExcel[i]))\n",
    "    worksheet.write(row, col + 1, str(y[i]))\n",
    "    row += 1\n",
    "\n",
    "worksheet = workbook.add_worksheet('Veer_mean')\n",
    "\n",
    "# Some data we want to write to the worksheet.\n",
    "#x = Dates[years_i[0]: years_i[1]]\n",
    "y = Daily_discharge_average\n",
    "\n",
    "\n",
    "\n",
    "# Start from the first cell. Rows and columns are zero indexed.\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "# Iterate over the data and write it out row by row.\n",
    "for i in range(len(x)):\n",
    "    worksheet.write(row, col,     str(x_forExcel[i]))\n",
    "    worksheet.write(row, col + 1, str(y[i]))\n",
    "    row += 1\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "##TODO: Leap years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = 'Test_irrigation.xlsx'\n",
    "\n",
    "book = xlrd.open_workbook(filename)\n",
    "sheet = book.sheet_by_index(0)\n",
    "num_rows = sheet.nrows\n",
    "\n",
    "Dates_fromExcel = [sheet.cell(row,0).value for row in range(0, num_rows)]\n",
    "#Dates_fromExcel2 = [i.split()[0].split('-') for i in Dates_fromExcel]\n",
    "#Dates = [datetime.datetime(int(d[0]), int(d[1]), int(d[2])) for d in Dates_fromExcel2]\n",
    "\n",
    "#Levels = [sheet.cell(row, 1).value for row in range(2, num_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratios_fromExcel = [float(sheet.cell(row, 1).value) for row in range(0, num_rows)]\n",
    "Dates_fromExcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(years_i)-1):\n",
    "\n",
    "    fig.add_trace(go.Scatter(x = [0,1],\n",
    "                             y = [mean(Volumes[years_i[i]: years_i[i+1]])]*2,\n",
    "                             mode='lines',\n",
    "                             name='Measured'))\n",
    "\n",
    "Daily_discharge_average = [mean([Volumes[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)]\n",
    "\n",
    "fig.add_trace(go.Scatter(x = [0,1],\n",
    "                         y = [mean(Daily_discharge_average)]*2,\n",
    "                         mode='lines',\n",
    "                         name='Measured'))\n",
    "\n",
    "fig.add_trace(go.Box(y = [mean(Volumes[years_i[i]: years_i[i+1]]) for i in range(len(years_i)-1)]))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig2 = go.Figure()\n",
    "\n",
    "for i in range(len(years_i)-1):\n",
    "\n",
    "    fig2.add_trace(go.Scatter(x = [0,1],\n",
    "                             y = [mean(Irr_overVolume[years_i[i]: years_i[i+1]])]*2,\n",
    "                             mode='lines',\n",
    "                             name='Measured'))\n",
    "\n",
    "Daily_discharge_average = [mean([Irr_overVolume[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)]) for day in range(365)]\n",
    "\n",
    "fig2.add_trace(go.Scatter(x = [0,1],\n",
    "                         y = [mean(Daily_discharge_average)]*2,\n",
    "                         mode='lines',\n",
    "                         name='Measured'))\n",
    "\n",
    "fig2.add_trace(go.Scatter(x = [0,1],\n",
    "                         y = [mean(Daily_discharge_median)]*2,\n",
    "                         mode='lines',\n",
    "                         name='Median'))\n",
    "\n",
    "fig2.add_trace(go.Box(y = [mean(Irr_overVolume[years_i[i]: years_i[i+1]]) for i in range(len(years_i)-1)]))\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.tips()\n",
    "fig = px.box(y=[mean(Volumes[years_i[i]: years_i[i+1]]) for i in range(len(years_i)-1)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[Volumes[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)] for day in range(2)]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for day in range(365):\n",
    "\n",
    "    fig.add_trace(go.Box(y = [Volumes[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)])) \n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig2 = go.Figure()\n",
    "\n",
    "for day in range(365):\n",
    "\n",
    "    fig2.add_trace(go.Box(y = [Irr_overVolume[years_i[year_i] : years_i[year_i + 1]][day] for year_i in range(len(years_i)-1)])) \n",
    "\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "x = np.array(range(365)) #Dates[years_i[0]: years_i[1]]\n",
    "y = np.array(Daily_discharge_median)\n",
    "\n",
    "# transforming the data to include another axis\n",
    "x = x[:, np.newaxis]\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=8)\n",
    "x_poly = polynomial_features.fit_transform(x)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, y)\n",
    "y_poly_pred = model.predict(x_poly)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y,y_poly_pred))\n",
    "r2 = r2_score(y,y_poly_pred)\n",
    "print(rmse)\n",
    "print(r2)\n",
    "\n",
    "plt.scatter(x, y, s=10)\n",
    "# sort the values of x before line plot\n",
    "sort_axis = operator.itemgetter(0)\n",
    "sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\n",
    "x, y_poly_pred = zip(*sorted_zip)\n",
    "plt.plot(x, y_poly_pred, color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "x = np.array(range(365))\n",
    "y = np.array(Daily_discharge_average)\n",
    "\n",
    "# transforming the data to include another axis\n",
    "x = x[:, np.newaxis]\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=7)\n",
    "x_poly = polynomial_features.fit_transform(x)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, y)\n",
    "y_poly_pred = model.predict(x_poly)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y,y_poly_pred))\n",
    "r2 = r2_score(y,y_poly_pred)\n",
    "print(rmse)\n",
    "print(r2)\n",
    "\n",
    "plt.scatter(x, y, s=10)\n",
    "# sort the values of x before line plot\n",
    "sort_axis = operator.itemgetter(0)\n",
    "sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\n",
    "x, y_poly_pred = zip(*sorted_zip)\n",
    "plt.plot(x, y_poly_pred, color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
